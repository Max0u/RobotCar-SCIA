{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import cv2, os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import scipy\n",
    "from skimage import transform\n",
    "import preprocess\n",
    "from nvi_utils import random_shadow, random_brightness\n",
    "\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 66, 200, 3\n",
    "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "\n",
    "#from ironcar import Ironcar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Conv2D, Dropout, Dense, Flatten\n",
    "\n",
    "def build_model():                                                              \n",
    "    \"\"\"                                                                         \n",
    "    Modified NVIDIA model                                                       \n",
    "    \"\"\"                                                                         \n",
    "    model = Sequential()                                                        \n",
    "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE))           \n",
    "    model.add(Conv2D(24, 5, 5, activation='elu', subsample=(2, 2)))             \n",
    "    model.add(Conv2D(36, 5, 5, activation='elu', subsample=(2, 2)))             \n",
    "    model.add(Conv2D(48, 5, 5, activation='elu', subsample=(2, 2)))             \n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))                               \n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))                               \n",
    "    model.add(Dropout(0.5))                                                     \n",
    "    model.add(Flatten())                                                        \n",
    "    model.add(Dense(100, activation='elu'))                                     \n",
    "    model.add(Dense(50, activation='elu'))                                      \n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dense(1))                                                      \n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"./models/model-0,5YUV.h5\"\n",
    "model = build_model()\n",
    "model.load_weights(model_name)\n",
    "\n",
    "img = cv2.imread(\"../AutoCar/road_simulator/src/dataset_simulator/frame_1402_gas_0.5_dir_0.20146169281252368.jpg\")\n",
    "img = transform.resize(img, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "# replace random_shadow by random_brightness to test brightness\n",
    "shadow = random_shadow(img)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# RGB TO BGR for plt\n",
    "img_disp = img[:, :, ::-1]\n",
    "shadow_disp = shadow[:, :, ::-1]\n",
    "plt.imshow(img_disp)\n",
    "plt.figure()\n",
    "plt.imshow(shadow_disp)\n",
    "\n",
    "model.predict(np.array([preprocess.rgb2yuv(img), preprocess.rgb2yuv(shadow)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"elu\", strides=(2, 2))`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"elu\", strides=(2, 2))`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"elu\", strides=(2, 2))`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "  \n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "C:\\ci\\opencv_1512688052760\\work\\modules\\imgproc\\src\\color.cpp:11010: error: (-215) depth == 0 || depth == 2 || depth == 5 in function cv::cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6140b271554a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIMAGE_HEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_WIDTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrgb2yuv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-6140b271554a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIMAGE_HEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_WIDTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrgb2yuv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\car_repo\\preprocess.py\u001b[0m in \u001b[0;36mrgb2yuv\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mConvert\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mRGB\u001b[0m \u001b[0mto\u001b[0m \u001b[0mYUV\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mThis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mdoes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \"\"\"\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2YUV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\ci\\opencv_1512688052760\\work\\modules\\imgproc\\src\\color.cpp:11010: error: (-215) depth == 0 || depth == 2 || depth == 5 in function cv::cvtColor\n"
     ]
    }
   ],
   "source": [
    "model_name = \"./models/model-0,0YUV.h5\"\n",
    "model = build_model()\n",
    "model.load_weights(model_name)\n",
    "\n",
    "funs = [(lambda x: x), random_shadow, random_brightness]\n",
    "root = \"../AutoCar/road_simulator/src/dataset_simulator/\"\n",
    "res = []\n",
    "\n",
    "for fun, i in zip(funs, range(len(funs))):\n",
    "    files = [root + f for f in listdir(root) if isfile(join(root, f))]\n",
    "    imgs = [ img for img in map(cv2.imread, files) ]\n",
    "    imgs = [ img for img in map(lambda x: transform.resize(x, (IMAGE_HEIGHT, IMAGE_WIDTH)), imgs)]\n",
    "    imgs = [ img for img in map(fun, imgs)]\n",
    "    imgs = [ img for img in map(preprocess.rgb2yuv, imgs)]\n",
    "    \n",
    "    prediction = model.predict(np.array(imgs))\n",
    "    res.append(prediction)\n",
    "    \n",
    "print(\"shadow\")\n",
    "diff = abs(res[0] - res[1])\n",
    "mean = np.mean(diff)\n",
    "print(mean)\n",
    "\n",
    "df = pd.DataFrame(diff, index=['Row'+str(i) for i in range(len(diff))])\n",
    "print(df.describe())\n",
    "\n",
    "print(\"light\")\n",
    "diff2 = abs(res[0] - res[2])\n",
    "mean2 = np.mean(diff2)\n",
    "print(mean2)\n",
    "\n",
    "df2 = pd.DataFrame(diff2, index=['Row'+str(i) for i in range(len(diff2))])\n",
    "print(df2.describe())\n",
    "\n",
    "\"\"\"\n",
    "for f in files:\n",
    "    file_path = root + f\n",
    "    img = cv2.imread(file_path)\n",
    "    img = np.array([img])\n",
    "    prediction.append(model.predict(img))\n",
    "\n",
    "\n",
    "root = \"./blur/\"\n",
    "files = [f for f in listdir(root) if isfile(join(root, f))]\n",
    "blur_pred = []\n",
    "\n",
    "for f in files:\n",
    "    file_path = root + f\n",
    "    img = mpimg.imread(file_path)\n",
    "    img = np.array([img])\n",
    "    blur_pred.append(model.predict(img))\n",
    "\n",
    "print(np.array(prediction))\n",
    "#print(np.array(blur_pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.idxmax())\n",
    "print(files[4302])\n",
    "\n",
    "print(df2.idxmax())\n",
    "print(files[4391])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
